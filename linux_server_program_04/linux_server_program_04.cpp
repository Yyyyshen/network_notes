// linux_server_program_04.cpp : 此文件包含 "main" 函数。程序执行将在此处开始并结束。
//

#include <iostream>

//
//高性能服务器程序框架
//

//
//服务器程序一般原理中，可解构三个模块
// I/O处理单元，有四种I/O模型和两种高效事件处理模式
// 逻辑单元，两种高效并发模式，以及高效逻辑处理方式——有限状态机
// 存储单元，可选模块
//

//
//服务器模型
// 
//C/S
// TCP/IP协议在设计和实现上没有客户端和服务端的概念，通信中机器是对等的
// 但资源被数据提供者拥有，所以几乎大家都自然的采用了C/S模型，所有客户端通过访问服务器获取资源
// 服务器启动后，创建监听socket（一个或多个），并调用bind函数绑定到端口上，然后调用listen开始监听
// 客户端创建连接socket后通过connect发起连接
// 服务端通过accept，加上某种I/O模型处理这些客户端连接，分配一个逻辑单元给新的连接服务（子进程、子线程或其他）
// 
//P2P
// 点对点，比C/S模型更符合网络通信实际情况，不需要服务器为中心，所有主机直接对等
// 每台机器消耗服务也提供服务，资源能充分自由地共享，但用户之间传输过多时，负载很重
// 并且存在一个问题，主机之间很难互相发现，所以通常带有一个专门地发现服务器
// 所以，也可以看作C/S模型扩展，每台主机既是客户端又是服务器
//

//
//编程框架
// 服务器基本模块功能
// 模块           单个服务器           服务器集群
// I/O处理        处理连接、读写数据   接入服务器、负载均衡
// 逻辑单元       业务进程或线程	   逻辑服务器
// 存储单元		  本地db、文件、缓存   数据库服务器
// 请求队列		  各单元通信方式	   各服务器之间的永久TCP连接
//

//
//I/O模型
// socket创建的时候默认是阻塞的
// 可以给socket函数第二个参数加上SOCK_NONBLOCK标志，或通过fcntl的F_SETFL命令设置非阻塞
// 不仅是socket，所有文件描述符都可以应用这个概念，根据这一点，分为阻塞I/O和非阻塞I/O
// 
// 阻塞I/O执行的系统调用会因为无法立即完成被系统挂起，直到等待的事件发生
// 比如connect，首先发送同步报文给服务器，等待服务器返回确认报文，如果这个过程因为网络条件差等原因较慢，则会阻塞在调用处，直到收到确认报文或超时
// 
// 非阻塞I/O总是立即返回，不管事件是否发生，如果没有发生，返回-1，此时-1与错误时返回一样，需要根据errno区分
// 对于accept、send、recv，事件未发生时errno通常设置成EAGAIN或EWOULDBLOCK（值一样，表示重试或期望阻塞）
// 对于connect，一般被设置成EINPROGRESS（在处理中）
// 
// 事件发生后才处理非阻塞I/O才能提高效率，因此，非阻塞I/O需要与I/O通知机制一起用，比如I/O复用和SIGIO信号
// I/O复用常用I/O通知机制，通过复用函数向内核注册一组事件，内核通过复用函数把就绪的事件通知给应用程序
// 常用的函数有select、poll、epoll_wait，I/O复用函数本身是阻塞的，提高效率的原因是它可以同时监听多个I/O事件
// SIGIO信号也可以报告I/O事件，可以为目标fd指定宿主进程，被指定的进程将捕获SIGIO信号，当fd有事件发生，SIGIO处理函数触发
// 
// 理论上，阻塞I/O、I/O复用和信号驱动I/O都是同步I/O模型，因为读写操作都是在I/O事件发生后由应用程序完成
// POSIX规范定义的异步I/O模型中，应该是用户可以直接对I/O操作执行读写，告诉内核自己读写缓冲区的位置，接下来就是内核接管
// 同步I/O通知给应用的是就绪事件，异步I/O向应用通知的是I/O完成事件 ***
//

//
//两种高效的事件处理模式
// 服务器通常需要处理三类事件，I/O事件、信号、定时事件
// 同步I/O模型通常用于实现Reactor模式
// 异步I/O模型则用于实现Proactor模式
// 也可以使用同步I/O方式模拟出Proactor模式
// 
//Reactor
// 要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生
// 有就立即将该事件通知工作线程（逻辑单元），除此之外主线程不做其他实质性工作
// 读写、接收新连接、处理请求等在工作线程完成
// 
// 同步I/O模型实现Reactor模式的流程（使用epoll_wait为例）
//	主线程向epoll内核事件表中注册socket读就绪事件
//	主线程调用epoll_wait等待socket上有数据可读
//	触发事件后，epoll_wait通知主线程，主线程将可读事件放入请求队列
//	请求队列上某个工作线程被唤醒，从socket读取数据，处理客户请求，然后向epoll内核事件表注册socket写事件就绪事件
//	主线程epoll_wait等待socket可写，触发时将可写事件放入请求队列
//	请求队列某工作线程被唤醒，向socket写数据，返回请求结果
// 
//Proactor
// 与Reactor模式不同，将所有I/O操作都交给主线程和内核，工作线程仅负责业务逻辑
// 
// 异步I/O模型实现Proactor模式的流程（以aio_read、aio_write为例）
//	主线程调用aio_read函数向内核注册socket上的读完成事件，告知读缓冲区位置，以及读完成时的通知方式（信号）
//	主线程继续处理其他逻辑
//	当socket数据被读入用户缓冲区后，内核通知应用程序，表示数据可用
//	应用程序通过预先定义好的处理函数选择一个工作线程处理请求
//	工作线程完成处理后，调用aio_write函数向内核注册写完成事件，告知写缓冲区位置，以及写完成时的通知方式
//	主线程继续处理其他逻辑
//	当用户缓冲区数据写入socket后，内核通知应用程序，表示数据发送完毕
//	应用程序通过预先定义好的处理函数选择一个工作线程做善后处理（继续接收或关闭socket等）
// 
//同步I/O模拟Proactor模式
// 原理是主线程执行数据读写操作，完成后，主线程通知工作线程模拟“事件完成”
// 从工作线程的角度，就是直接获取了读写结果，只需要对读写结果进行逻辑处理
// 
// 使用同步I/O模型模拟Proactor模式的流程（以epoll_wait为例）
//	主线程向epoll内核事件表注册socket读就绪事件
//	主线程调用epoll_wait等待数据可读
//	触发事件后，epoll_wait通知主线程，主线程从socket循环读取数据，完全读完后将数据封装为请求对象插入请求队列
//	请求队列上某个工作线程被唤醒，拿到请求对象做业务处理，然后向epoll内核事件表注册socket写就绪事件
//	主线程epoll_wait等待socket可写
//	触发事件后，epoll_wait通知主线程，主线程向socket上写入请求队列处理后的请求结果
//

//
//两种高效并发模式
// 并发的目的是让程序同时执行多个任务
// 如果程序计算密集，并发并没有优势，反而会因为任务切换降低效率
// 如果是I/O密集型，经常读写文件访问数据库等，则I/O速度远没有CPU速度快，阻塞在I/O的操作浪费大量CPU时间
// 当有多个执行线程，则当前线程被I/O阻塞时可主动让出CPU（或系统调度），并转移执行权到其他线程，当I/O操作完成再继续
// 
// 并发通常有多进程和多线程（现在还有协程、纤程等）
// 并发模式指I/O处理单元和多个逻辑单元之间协调完成任务的方式
// 服务器主要有两种
//	半同步/半异步（half-sync/half-async）模式
//	领导者/追随者（Leader/Followers）模式
// 
//半同步/半异步
// 此处同步异步和I/O中的同步和异步不同
// I/O中指的是内核向应用程序通知是何种I/O事件（就绪或完成），谁来完成I/O读写（应用还是内核）
// 并发中，同步指的是程序按照代码序列顺序执行，异步指的是程序执行需要系统事件来驱动（中断、信号等）
// 
// 同步方式运行的线程是同步线程，编写简单，效率相对较低，实时性差些
// 异步方式运行的线程是异步线程，逻辑相对复杂，难调试和扩展，不适合大量并发
// 服务器则既要求较好的实时性，有要求能同时处理很多客户端请求
// 就需要结合起来，同时使用两种线程，即半同步/半异步模式
// 
// 此模式中，同步线程处理客户逻辑，相当于逻辑单元
// 异步线程处理I/O事件，相当于I/O处理单元
// 异步线程监听请求，将数据封装为请求对象，插入请求队列；请求队列通知某工作在同步模式的工作线程读取并处理请求对象
// 选择哪个工作线程为请求服务则取决与请求队列设计，最简单的就是轮询调度，也可以通过条件变量或信号量随机选取
// 
// 综合考虑处理事件模式和I/O模型，则半同步/半异步存在一些变体
// 半同步/半反应堆（half-sync/half-reactive）模式 就是一种变体
//	异步线程只有一个，主线程充当，负责监听所有socket上的事件
//	监听事件有可读事件即新连接到来，主线程接受后得到新的连接socket，之后向epoll内核事件表注册该socket的读写事件
//	如果连接socket上有读写事件发生，代表客户请求到来或需要发送数据到客户端，主线程则将该socket插入请求队列
//	睡眠在请求队列中的所有工作线程通过竞争获得任务管理权（互斥锁，只有空闲线程才会来处理新任务）
// 主线程插入队列的任务是socket，说明事件处理是reactor，工作线程自己从socket上读写（也可以使用模拟的Proactor）
// 存在缺点
//	主线程和工作线程共享请求队列，主线程添加或工作线程取出需要加锁，有一定的CPU时间浪费
//	每个工作线程只能处理一个客户请求，如果连接很多，请求队列将会堆积；单纯增加工作线程数量，也会因为线程切换消耗大量CPU时间
// 
// 一种相对高效的半同步/半异步模式，每个工作线程能同时处理多个客户连接
//	主线程只负责管理监听socket，连接socket由工作线程管理
//	新连接到来时，主线程接受并将返回的socket派发给某个工作线程
//	后续直到客户连接关闭，该socket上的任何I/O操作都由被选中的工作线程处理
//	主线程派发socket最简单的方式是管道，向管道写数据，工作线程检测到管道可读，分析是否是新客户连接到来
//	如果是，则把新socket上的读写时间注册到自己的epoll内核事件表，这样当一个连接空闲时，还可以接收下一个连接
// 这个模式下，主线程和工作线程分别维护自己的事件循环，各自独立监听不同事件
// 理论上，每个线程其实都是工作在异步模式，并非严格的半同步/半异步模式
// 
//领导者/追随者模式
// 多个工作线程轮流获得事件源集合，轮流监听、分发并处理事件的一种模式
// 任意时间点，程序仅有一个领导者线程，负责监听I/O事件，其他线程都是追随者
// 休眠在线程池中的追随者等待称为新的领导者
// 当前领导者检测到I/O事件，先从线程池选出新的领导线程
// 新的领导线程继续检测I/O事件，而原来的领导者开始处理I/O事件，让出领导权
// 这样不同的线程实现了并发
// 
// 此模式组件
//	句柄集、线程集、事件处理器、具体事件处理器
// 句柄用于表示I/O资源，Linux通常就是一个fd，句柄集管理大量句柄，使用wait_for_event方法监听句柄上的I/O事件
//	就绪后，通知给领导线程，领导者调用绑定在句柄上的事件处理器来处理事件
// 线程集时所有工作线程的管理者，负责个线程之间的同步、新领导的推选
//	线程在任一事件都处于三种状态之一
//	Leader 领导者身份，负责等待句柄集上的I/O事件
//	Processing 正在处理事件，是领导者检测到事件后的状态；也可能指定其他追随者处理事件，自己依然是领导者
//	Follower 追随者，等待称为新领导或被指定完成新任务
// 事件处理器和具体事件处理器
//	通常包括一个或多个回调函数，用于处理业务逻辑，事件处理器会事先绑定到某个句柄
//	具体事件处理器则是一个派生类，处理特定任务
// 
// 领导者线程自己监听I/O事件并处理请求，因此不需要线程之间传递额外数据
// 无须在线程之间同步对请求队列的访问
// 但缺点是仅支持一个事件源集合，无法让每个工作线程独立管理多个客户连接
//

//
//
//

int main()
{
	std::cout << "Hello World!\n";
}
